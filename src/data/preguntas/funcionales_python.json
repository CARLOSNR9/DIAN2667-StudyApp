[
  {
    "id": "py-1",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita crear un script de Python que almacene el NIT y el nombre de los contribuyentes en un formato de clave: valor. ¿Qué estructura de datos nativa de Python es la más adecuada para esta tarea?",
    "opciones": [
      "A. Una lista de Python, ya que es una colección ordenada y mutable de elementos.",
      "B. Un diccionario de Python, ya que almacena pares clave: valor de forma eficiente.",
      "C. Una tupla de Python, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Un diccionario de Python es la estructura de datos más adecuada para almacenar pares clave: valor, como el NIT y el nombre de los contribuyentes. El diccionario permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-2",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un analista de la DIAN necesita un script de Python que lea un archivo CSV con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. pd.read_json()",
      "B. pd.read_sql()",
      "C. pd.read_csv()"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "La función pd.read_csv() de la biblioteca pandas es la más adecuada para leer archivos en formato CSV y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-3",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el total de impuesto_liquidado por nit_contribuyente de las declaraciones pendientes. ¿Qué combinación de funciones de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. df.groupby('nit_contribuyente')['impuesto_liquidado'].sum()",
      "B. df.loc[df['estado'] == 'Pendiente'].groupby('nit_contribuyente')['impuesto_liquidado'].sum()",
      "C. df['impuesto_liquidado'].sum()"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La combinación de loc y groupby() de pandas es la más adecuada para esta tarea. El método loc filtra los registros con estado 'Pendiente', y groupby() agrupa los datos por 'nit_contribuyente' para sumar el impuesto, lo que genera un reporte confiable."
  },
  {
    "id": "py-4",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe automatizar la limpieza de un DataFrame que contiene registros con valores nulos en un campo crítico. ¿Qué función de la biblioteca pandas es la más adecuada para identificar y tratar estos valores nulos de forma eficiente?",
    "opciones": [
      "A. df.fillna() o df.dropna()",
      "B. df.replace()",
      "C. df.loc[]"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Las funciones fillna() y dropna() de pandas son las más adecuadas para identificar y tratar los valores nulos en un DataFrame. fillna() permite reemplazar los valores nulos con un valor específico, mientras que dropna() permite eliminarlos, lo que asegura la calidad de los datos para el análisis."
  },
  {
    "id": "py-5",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita extraer datos de contribuyentes de múltiples bases de datos, pero algunas bases tienen datos desactualizados. ¿Qué debe hacer durante la extracción de los datos?",
    "opciones": [
      "A. Extraer solo los datos más recientes y omitir los desactualizados.",
      "B. Validar y extraer solo los datos más relevantes, asegurando que sean consistentes con las fuentes actualizadas.",
      "C. Ignorar los datos desactualizados y proceder con la extracción de todos los registros."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El Gestor II debe validar y extraer solo los datos relevantes y actualizados para asegurar que el proceso ETL sea eficiente y los datos sean útiles para el análisis posterior."
  },

  
  {
    "id": "py-6",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está escribiendo un script de Python para almacenar la información de los contribuyentes. La información de cada contribuyente incluye el NIT (que es único) y el nombre. ¿Qué estructura de datos nativa de Python es la más adecuada para almacenar esta información?",
    "opciones": [
      "A. Una lista, ya que es una colección ordenada y mutable de elementos.",
      "B. Un diccionario, ya que almacena pares `clave: valor` de forma eficiente.",
      "C. Una tupla, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Un diccionario es la estructura de datos más adecuada para almacenar pares `clave: valor`, como el NIT (clave) y el nombre (valor) de los contribuyentes. Esta estructura permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-7",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita escribir un script de Python que lea un archivo CSV con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "La función `pd.read_csv()` de la biblioteca pandas es la más adecuada para leer archivos en formato CSV y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-8",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un analista de la DIAN necesita un script de Python que lea un archivo CSV con registros aduaneros y que extraiga solo la columna de `país_origen`. ¿Qué método de la biblioteca pandas es el más adecuado para esta tarea?",
    "opciones": [
      "A. `df.loc[:, 'pais_origen']`",
      "B. `df.iloc[:, 0]`",
      "C. `df.iloc[0, 0]`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El método `df.loc[]` es la forma más adecuada de seleccionar datos de un DataFrame por etiquetas de fila y columna. En este caso, `df.loc[:, 'pais_origen']` selecciona todas las filas (`:`) y solo la columna `'pais_origen'`."
  },
  {
    "id": "py-9",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número total de registros en un DataFrame de declaraciones tributarias. ¿Qué método de la biblioteca pandas es el más adecuado para esta tarea?",
    "opciones": [
      "A. `df.count()`",
      "B. `df.shape[0]`",
      "C. `df.sum()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El método `df.shape[0]` devuelve el número de filas en un DataFrame, lo que es igual al número total de registros. El método `df.count()` cuenta los valores no nulos por columna, por lo que no es adecuado para la solicitud."
  },
  {
    "id": "py-10",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere estandarizar un campo de `valor` de `texto` a `numérico`. ¿Qué tipo de dato de Python es el más adecuado para el campo `valor` después de la estandarización?",
    "opciones": [
      "A. `str`",
      "B. `int` o `float`",
      "C. `bool`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Los tipos de datos `int` (enteros) y `float` (decimales) son los más adecuados para almacenar valores numéricos. En este caso, el campo `valor` después de la estandarización debe ser numérico para permitir operaciones de agregación."
  },
  {
    "id": "py-11",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita escribir un script de Python que lea un archivo JSON con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La función `pd.read_json()` de la biblioteca pandas es la más adecuada para leer archivos en formato JSON y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-12",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros con un `estado` 'Pagado' en un DataFrame de declaraciones tributarias. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['estado'] == 'Pagado'].shape[0]`",
      "B. `df.groupby('estado')['estado'].count()`",
      "C. `df['estado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con estado 'Pagado', y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con estado 'Pagado'."
  },
  {
    "id": "py-13",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere anonimizar ciertos datos personales de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-14",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita escribir un script de Python que lea un archivo Excel con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_excel()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La función `pd.read_excel()` de la biblioteca pandas es la más adecuada para leer archivos en formato Excel y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-15",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor a 1000. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['impuesto_liquidado'] > 1000].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor a 1000, y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con un `impuesto_liquidado` mayor a 1000."
  },
  {
    "id": "py-16",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el diseño de un nuevo proceso, necesita almacenar los datos de facturación electrónica en un formato de `clave: valor`, donde la `clave` es el `id_factura` y el `valor` es la información del documento electrónico. ¿Qué estructura de datos nativa de Python es la más adecuada para esta tarea?",
    "opciones": [
      "A. Un diccionario de Python, ya que almacena pares `clave: valor` de forma eficiente.",
      "B. Una lista de Python, ya que es una colección ordenada y mutable de elementos.",
      "C. Una tupla de Python, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Un diccionario de Python es la estructura de datos más adecuada para almacenar pares `clave: valor`. En este caso, el `id_factura` es la clave y la información del documento electrónico es el valor. Esta estructura permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-17",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo SQL con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La función `pd.read_sql()` de la biblioteca pandas es la más adecuada para leer archivos en formato SQL y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-18",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado`. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['impuesto_liquidado'] > df['impuesto_liquidado'].mean()].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor al promedio, y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con un `impuesto_liquidado` mayor al promedio."
  },
  {
    "id": "py-19",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere anonimizar ciertos datos personales de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-20",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo XML con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_xml()`"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "La función `pd.read_xml()` de la biblioteca pandas es la más adecuada para leer archivos en formato XML y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-21",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor a 1000 y que se encuentran en estado 'Pendiente'. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[(df['impuesto_liquidado'] > 1000) & (df['estado'] == 'Pendiente')].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor a 1000 y estado 'Pendiente', y `shape[0]` devuelve el número de filas del DataFrame filtrado."
  },
  {
    "id": "py-22",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el diseño de un nuevo proceso, necesita almacenar los datos de facturación electrónica en un formato de `clave: valor`, donde la `clave` es el `id_factura` y el `valor` es la información del documento electrónico. ¿Qué estructura de datos nativa de Python es la más adecuada para esta tarea?",
    "opciones": [
      "A. Un diccionario de Python, ya que almacena pares `clave: valor` de forma eficiente.",
      "B. Una lista de Python, ya que es una colección ordenada y mutable de elementos.",
      "C. Una tupla de Python, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Un diccionario de Python es la estructura de datos más adecuada para almacenar pares `clave: valor`. En este caso, el `id_factura` es la clave y la información del documento electrónico es el valor. Esta estructura permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-23",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo SQL con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La función `pd.read_sql()` de la biblioteca pandas es la más adecuada para leer archivos en formato SQL y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-24",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado`. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['impuesto_liquidado'] > df['impuesto_liquidado'].mean()].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor al promedio, y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con un `impuesto_liquidado` mayor al promedio."
  },
  {
    "id": "py-25",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere anonimizar ciertos datos personales de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
   {
    "id": "py-26",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que combine la tabla `Declaraciones_Tributarias` con la tabla `Contribuyentes` para mostrar el nombre del contribuyente y el total de impuestos liquidados. Ambas tablas se relacionan por el campo `nit_contribuyente`. ¿Qué función de la biblioteca pandas es la más adecuada para combinar estos DataFrames?",
    "opciones": [
      "A. `pd.join()`",
      "B. `pd.merge()`",
      "C. `pd.concat()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La función `pd.merge()` de la biblioteca pandas es la más adecuada para combinar DataFrames por una columna en común (`nit_contribuyente`). Esta función realiza una operación de `JOIN`, que es ideal para la solicitud."
  },
  {
    "id": "py-27",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre los `nit` de los contribuyentes que no han realizado ninguna declaración tributaria. Para ello, necesita combinar la tabla `Declaraciones_Tributarias` con la tabla `Contribuyentes`. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `pd.merge(df1, df2, on='nit_contribuyente', how='left')` y luego filtrar los registros nulos en la columna de la segunda tabla.",
      "B. `pd.merge(df1, df2, on='nit_contribuyente', how='inner')` y luego filtrar los registros que no tienen una coincidencia.",
      "C. `pd.merge(df1, df2, on='nit_contribuyente', how='right')` y luego filtrar los registros nulos en la columna de la primera tabla."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `pd.merge()` con `how='left'` es la más adecuada para esta tarea. Esta función realiza un `LEFT JOIN` que devuelve todos los registros de la primera tabla, independientemente de la coincidencia. El `DataFrame` resultante se puede filtrar para encontrar los registros nulos, que son los que no tienen una declaración tributaria."
  },
  {
    "id": "py-28",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la limpieza de datos, necesita eliminar todos los registros de un DataFrame que tienen valores duplicados en el campo `nit_contribuyente`. ¿Qué método de la biblioteca pandas es el más adecuado para esta tarea?",
    "opciones": [
      "A. `df.drop_duplicates(subset=['nit_contribuyente'])`",
      "B. `df.drop(columns=['nit_contribuyente'])`",
      "C. `df.fillna(value=0)`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El método `df.drop_duplicates()` de pandas es el más adecuado para eliminar registros duplicados de un DataFrame. El argumento `subset` especifica las columnas que se deben utilizar para identificar los duplicados, en este caso, el `nit_contribuyente`."
  },
  {
    "id": "py-29",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el total de `impuesto_liquidado` por cada `nit_contribuyente` que tiene más de 10 declaraciones tributarias. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.groupby('nit_contribuyente')['impuesto_liquidado'].sum()`",
      "B. `df.groupby('nit_contribuyente').filter(lambda x: len(x) > 10)['impuesto_liquidado'].sum()`",
      "C. `df.loc[df['impuesto_liquidado'] > 10]['impuesto_liquidado'].sum()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La combinación de `groupby()` y `filter()` de pandas es la más adecuada para esta tarea. El método `groupby()` agrupa los datos por `nit_contribuyente`, y `filter()` filtra los grupos que tienen más de 10 declaraciones tributarias. Luego, se suma el `impuesto_liquidado` de los grupos filtrados, lo que genera un reporte confiable."
  },
  {
    "id": "py-30",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el diseño de un nuevo proceso, necesita almacenar los datos de facturación electrónica en un formato de `clave: valor`, donde la `clave` es el `id_factura` y el `valor` es la información del documento electrónico. ¿Qué estructura de datos nativa de Python es la más adecuada para esta tarea?",
    "opciones": [
      "A. Un diccionario de Python, ya que almacena pares `clave: valor` de forma eficiente.",
      "B. Una lista de Python, ya que es una colección ordenada y mutable de elementos.",
      "C. Una tupla de Python, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Un diccionario de Python es la estructura de datos más adecuada para almacenar pares `clave: valor`. En este caso, el `id_factura` es la clave y la información del documento electrónico es el valor. Esta estructura permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-31",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado`. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['impuesto_liquidado'] > df['impuesto_liquidado'].mean()].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor al promedio, y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con un `impuesto_liquidado` mayor al promedio."
  },
  {
    "id": "py-32",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere anonimizar ciertos datos personales de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-33",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo XML con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_xml()`"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "La función `pd.read_xml()` de la biblioteca pandas es la más adecuada para leer archivos en formato XML y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-34",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor a 1000 y que se encuentran en estado 'Pendiente'. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[(df['impuesto_liquidado'] > 1000) & (df['estado'] == 'Pendiente')].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor a 1000 y estado 'Pendiente', y `shape[0]` devuelve el número de filas del DataFrame filtrado."
  },
  {
    "id": "py-35",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el total de `impuesto_liquidado` por cada `nit_contribuyente` que tiene más de 10 declaraciones tributarias. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.groupby('nit_contribuyente')['impuesto_liquidado'].sum()`",
      "B. `df.groupby('nit_contribuyente').filter(lambda x: len(x) > 10)['impuesto_liquidado'].sum()`",
      "C. `df.loc[df['impuesto_liquidado'] > 10]['impuesto_liquidado'].sum()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La combinación de `groupby()` y `filter()` de pandas es la más adecuada para esta tarea. El método `groupby()` agrupa los datos por `nit_contribuyente`, y `filter()` filtra los grupos que tienen más de 10 declaraciones tributarias. Luego, se suma el `impuesto_liquidado` de los grupos filtrados, lo que genera un reporte confiable."
  },
  {
    "id": "py-36",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el diseño de un nuevo proceso, necesita almacenar los datos de facturación electrónica en un formato de `clave: valor`, donde la `clave` es el `id_factura` y el `valor` es la información del documento electrónico. ¿Qué estructura de datos nativa de Python es la más adecuada para esta tarea?",
    "opciones": [
      "A. Un diccionario de Python, ya que almacena pares `clave: valor` de forma eficiente.",
      "B. Una lista de Python, ya que es una colección ordenada y mutable de elementos.",
      "C. Una tupla de Python, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Un diccionario de Python es la estructura de datos más adecuada para almacenar pares `clave: valor`. En este caso, el `id_factura` es la clave y la información del documento electrónico es el valor. Esta estructura permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-37",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo SQL con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La función `pd.read_sql()` de la biblioteca pandas es la más adecuada para leer archivos en formato SQL y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-38",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado`. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['impuesto_liquidado'] > df['impuesto_liquidado'].mean()].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor al promedio, y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con un `impuesto_liquidado` mayor al promedio."
  },
  {
    "id": "py-39",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere anonimizar ciertos datos personales de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-40",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo XML con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_xml()`"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "La función `pd.read_xml()` de la biblioteca pandas es la más adecuada para leer archivos en formato XML y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-41",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor a 1000 y que se encuentran en estado 'Pendiente'. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[(df['impuesto_liquidado'] > 1000) & (df['estado'] == 'Pendiente')].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor a 1000 y estado 'Pendiente', y `shape[0]` devuelve el número de filas del DataFrame filtrado."
  },
  {
    "id": "py-42",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el diseño de un nuevo proceso, necesita almacenar los datos de facturación electrónica en un formato de `clave: valor`, donde la `clave` es el `id_factura` y el `valor` es la información del documento electrónico. ¿Qué estructura de datos nativa de Python es la más adecuada para esta tarea?",
    "opciones": [
      "A. Un diccionario de Python, ya que almacena pares `clave: valor` de forma eficiente.",
      "B. Una lista de Python, ya que es una colección ordenada y mutable de elementos.",
      "C. Una tupla de Python, ya que es una colección ordenada e inmutable de elementos."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Un diccionario de Python es la estructura de datos más adecuada para almacenar pares `clave: valor`. En este caso, el `id_factura` es la clave y la información del documento electrónico es el valor. Esta estructura permite acceder a los datos de forma eficiente a través de la clave."
  },
  {
    "id": "py-43",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que lea un archivo SQL con registros aduaneros. ¿Qué función de la biblioteca pandas es la más adecuada para leer este tipo de archivo y crear un DataFrame?",
    "opciones": [
      "A. `pd.read_json()`",
      "B. `pd.read_sql()`",
      "C. `pd.read_csv()`"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La función `pd.read_sql()` de la biblioteca pandas es la más adecuada para leer archivos en formato SQL y crear un DataFrame, lo que facilita el procesamiento y el análisis de los datos."
  },
  {
    "id": "py-44",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita un script de Python que cuente el número de registros en un DataFrame de declaraciones tributarias que tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado`. ¿Qué combinación de métodos de la biblioteca pandas es la más adecuada para esta tarea?",
    "opciones": [
      "A. `df.loc[df['impuesto_liquidado'] > df['impuesto_liquidado'].mean()].shape[0]`",
      "B. `df.groupby('impuesto_liquidado').count()`",
      "C. `df['impuesto_liquidado'].count()`"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La combinación de `loc` y `shape[0]` de pandas es la más adecuada para esta tarea. El método `loc` filtra los registros con un `impuesto_liquidado` mayor al promedio, y `shape[0]` devuelve el número de filas del DataFrame filtrado, que es el número de registros con un `impuesto_liquidado` mayor al promedio."
  },
  {
    "id": "py-45",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL que combina datos de facturación electrónica con registros aduaneros. El proceso requiere anonimizar ciertos datos personales de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },

  {
    "id": "py-46",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un script de Python que lea un archivo CSV con 10 millones de registros de facturación electrónica. El script debe procesar los datos por lotes para no saturar la memoria del servidor. ¿Qué parámetro de la función `pd.read_csv()` de la biblioteca pandas es el más adecuado para esta tarea?",
    "opciones": [
      "A. `chunksize`, que permite leer el archivo en fragmentos de un tamaño específico de la entidad.",
      "B. `nrows`, que permite leer un número específico de filas del archivo de la entidad.",
      "C. `skiprows`, que permite saltar un número específico de filas del archivo de la entidad."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El parámetro `chunksize` de `pd.read_csv()` es el más adecuado para esta tarea. Permite leer el archivo en fragmentos de un tamaño específico, lo que evita saturar la memoria del servidor y permite procesar los datos por lotes. Esto es crucial para manejar grandes volúmenes de datos en la DIAN."
  },
  {
    "id": "py-47",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-48",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-49",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-50",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-51",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-52",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-53",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-54",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-55",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-56",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-57",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-58",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-59",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-60",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-61",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-62",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-63",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-64",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-65",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-66",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-67",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-68",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-69",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-70",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-71",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-72",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
  {
    "id": "py-73",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe crear un reporte que muestre el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio del `impuesto_liquidado` de todas las declaraciones. ¿Qué tipo de consulta de SQL es el más adecuado para esta solicitud de la entidad?",
    "opciones": [
      "A. Una subconsulta para obtener el promedio del `impuesto_liquidado` de la entidad.",
      "B. Una consulta con `LEFT JOIN` y una subconsulta para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad.",
      "C. Una consulta con `INNER JOIN` y `WHERE` para obtener el nombre de los contribuyentes con un `impuesto_liquidado` mayor al promedio de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Una consulta con `LEFT JOIN` y una subconsulta es el tipo de consulta más adecuado para esta solicitud. Se utiliza para obtener los `nit_contribuyente` con un `impuesto_liquidado` mayor al promedio de la entidad y luego se utiliza un `LEFT JOIN` para obtener el nombre de los contribuyentes que tienen declaraciones pendientes y que no tienen un `impuesto_liquidado` mayor al promedio. Esto permite a la DIAN tomar decisiones informadas sobre la fiscalización."
  },
  {
    "id": "py-74",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está desarrollando un proceso ETL para la consolidación de datos en el **DataR**. El proceso debe manejar grandes volúmenes de datos de múltiples fuentes. Para asegurar la integridad de los datos, el proceso debe ser transaccional, es decir, si alguna parte de la carga falla, todos los cambios deben ser revertidos. ¿Qué comando de SQL es el que se utiliza para gestionar las transacciones en la base de datos?",
    "opciones": [
      "A. El comando `COMMIT` para guardar permanentemente los cambios de una transacción.",
      "B. El comando `ROLLBACK` para deshacer los cambios realizados en una transacción.",
      "C. Los comandos `COMMIT` y `ROLLBACK` para gestionar las transacciones en la base de datos."
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los comandos `COMMIT` y `ROLLBACK` son los que se utilizan para gestionar las transacciones en la base de datos. El comando `COMMIT` guarda permanentemente los cambios de una transacción, y el comando `ROLLBACK` deshace los cambios realizados en una transacción, lo que garantiza la integridad de los datos en el proceso ETL."
  },
  {
    "id": "py-75",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II, en el marco de la optimización de consultas, debe crear un índice en un campo de la tabla `Facturacion_Electronica` para acelerar la búsqueda de los registros. ¿Qué comando SQL es el más adecuado para crear un índice en la tabla de la entidad?",
    "opciones": [
      "A. CREATE INDEX idx_fecha ON Facturacion_Electronica (fecha_emision);",
      "B. CREATE INDEX idx_fecha ON Facturacion_Electronica;",
      "C. CREATE TABLE idx_fecha ON Facturacion_Electronica (fecha_emision);"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando 'CREATE INDEX' se utiliza para crear un índice en una tabla. La sintaxis correcta es 'CREATE INDEX nombre_indice ON nombre_tabla (columna)'. El uso de un índice en un campo de la tabla `Facturacion_Electronica` acelera la búsqueda de los registros, lo que mejora el rendimiento de los reportes de la entidad."
  },
{
    "id": "py-76",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué tipo de dato en Python se utiliza para almacenar una secuencia inmutable de elementos?",
    "opciones": [
      "A. Lista",
      "B. Tupla",
      "C. Diccionario"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Las tuplas son secuencias inmutables, ideales para almacenar datos que no deben modificarse, como códigos tributarios fijos."
  },
  {
    "id": "py-77",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Cuál es la salida de `print(type([]))` en Python?",
    "opciones": [
      "A. <class 'tuple'>",
      "B. <class 'list'>",
      "C. <class 'dict'>"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Los corchetes `[]` definen una lista en Python. Este conocimiento es esencial para manipular estructuras de datos en procesos ETL."
  },
  {
    "id": "py-78",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué método se usa para agregar un elemento al final de una lista en Python?",
    "opciones": [
      "A. append()",
      "B. insert()",
      "C. add()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El método `append()` añade elementos al final de una lista, útil para construir datasets incrementales en la DIAN."
  },
  {
    "id": "py-79",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué biblioteca de Python es más adecuada para trabajar con DataFrames?",
    "opciones": [
      "A. NumPy",
      "B. Pandas",
      "C. Matplotlib"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Pandas es la biblioteca estándar para manipulación de DataFrames, esencial en procesos de validación de datos tributarios."
  },
  {
    "id": "py-80",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué comando se usa para instalar la biblioteca Pandas en Python?",
    "opciones": [
      "A. pip install numpy",
      "B. pip install pandas",
      "C. pip install matplotlib"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El gestor de paquetes pip instala bibliotecas como Pandas, necesarias para análisis de datos en la DIAN."
  },
  {
    "id": "py-81",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué función se utiliza para leer un archivo CSV en Pandas?",
    "opciones": [
      "A. read_csv()",
      "B. read_excel()",
      "C. read_json()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "`read_csv()` es la función clave para cargar datos desde archivos CSV, formato común en reportes tributarios."
  },
  {
    "id": "py-82",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué estructura de Python permite almacenar pares clave-valor?",
    "opciones": [
      "A. Lista",
      "B. Tupla",
      "C. Diccionario"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Los diccionarios son ideales para mapear datos como NITs con sus respectivos valores fiscales."
  },
  {
    "id": "py-83",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué operador se usa para comentar una línea en Python?",
    "opciones": [
      "A. //",
      "B. #",
      "C. /*"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El símbolo `#` comenta líneas, práctica esencial para documentar scripts de procesamiento de datos."
  },
  {
    "id": "py-84",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué método de Pandas se usa para mostrar las primeras filas de un DataFrame?",
    "opciones": [
      "A. tail()",
      "B. head()",
      "C. describe()"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "`head()` permite una revisión rápida de datos, crucial para validar información cargada en procesos ETL."
  },
  {
    "id": "py-85",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué función se utiliza para crear un rango de números en Python?",
    "opciones": [
      "A. range()",
      "B. list()",
      "C. seq()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "`range()` genera secuencias numéricas, útiles para iterar sobre índices en operaciones de datos."
  },

  {
    "id": "py-96",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué método de Pandas se utiliza para filtrar filas donde el valor de la columna 'Impuesto' sea mayor a 1 millón?",
    "opciones": [
      "A. df[df['Impuesto'] > 1_000_000]",
      "B. df.filter('Impuesto' > 1_000_000)",
      "C. df.select(df['Impuesto'] > 1_000_000)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La indexación booleana en Pandas (`df[condición]`) es eficiente para filtrar datos fiscales relevantes."
  },
  {
    "id": "py-97",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Cómo se puede manejar valores faltantes en un DataFrame de Pandas antes de cargarlo a DataR?",
    "opciones": [
      "A. df.dropna()",
      "B. df.fillna(0)",
      "C. Ambas anteriores son válidas"
    ],
    "respuesta_correcta_index": 2,
    "explicacion": "Tanto `dropna()` como `fillna()` son métodos válidos, dependiendo de si se desean eliminar o imputar valores faltantes."
  },
  {
    "id": "py-98",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué función de Pandas permite agrupar datos por una columna y calcular estadísticas?",
    "opciones": [
      "A. groupby()",
      "B. pivot_table()",
      "C. merge()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "`groupby()` es esencial para análisis agregados, como sumar impuestos por sector económico."
  },
  {
    "id": "py-99",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Qué comando de Pandas se usa para cambiar el tipo de dato de una columna a entero?",
    "opciones": [
      "A. df['columna'] = df['columna'].str.to_int()",
      "B. df['columna'] = df['columna'].astype(int)",
      "C. df['columna'].convert_to_int()"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "`astype(int)` convierte tipos de datos, crucial para asegurar consistencia en campos numéricos como valores fiscales."
  },
  {
    "id": "py-100",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Cómo se puede concatenar verticalmente dos DataFrames en Pandas?",
    "opciones": [
      "A. pd.concat([df1, df2], axis=0)",
      "B. df1.join(df2)",
      "C. df1.merge(df2)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "`pd.concat()` con `axis=0` apila DataFrames, útil para consolidar datos de múltiples periodos tributarios."
  },

  {
    "id": "py-116",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Al implementar un pipeline ETL para facturas electrónicas, ¿qué técnica optimizaría el procesamiento de 1M+ archivos XML?",
    "opciones": [
      "A. Procesamiento por lotes con multiprocessing",
      "B. Carga secuencial con Pandas",
      "C. Uso exclusivo de iterrows()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El multiprocessing permite paralelizar tareas, reduciendo tiempo de procesamiento para grandes volúmenes de datos."
  },
  {
    "id": "py-117",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "¿Cómo garantizaría la idempotencia en un script que carga datos diarios a DataR?",
    "opciones": [
      "A. Usar transacciones SQL con rollback",
      "B. Implementar checksums para detectar duplicados",
      "C. Ejecutar el script múltiples veces al día"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "Los checksums verifican la unicidad de los datos, previniendo duplicados en cargas recurrentes."
  },
  {
    "id": "py-118",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para cumplir con BCBS 239 en reportes de riesgo fiscal, ¿qué propiedad debe tener un DataFrame de Pandas?",
    "opciones": [
      "A. Linaje de datos documentado",
      "B. Índices no únicos",
      "C. Columnas sin metadatos"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "BCBS 239 exige trazabilidad completa (linaje), documentando el origen y transformaciones de los datos."
  },

  {
    "id": "py-119",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita leer un archivo CSV de reportes tributarios en Python. ¿Cuál es la forma más directa de cargarlo en un DataFrame usando pandas?",
    "opciones": [
        "A. pd.load_csv('reporte.csv')",
        "B. pd.read_csv('reporte.csv')",
        "C. pandas.csv_read('reporte.csv')"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La función correcta es pd.read_csv(), que permite leer archivos CSV directamente en un DataFrame, siendo el método estándar en Python con pandas."
},
{
    "id": "py-120",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un script de la DIAN, se requiere recorrer una lista de NIT para validarlos. ¿Qué estructura de control de Python es la más adecuada?",
    "opciones": [
        "A. Un bucle for",
        "B. Una sentencia if",
        "C. Una función lambda"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El bucle for permite iterar sobre cada elemento de la lista de NIT y aplicar validaciones de manera secuencial y controlada."
},
{
    "id": "py-121",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "El Gestor II debe almacenar datos únicos de contribuyentes sin repeticiones. ¿Qué estructura de datos de Python debe usar?",
    "opciones": [
        "A. Lista",
        "B. Set",
        "C. Diccionario"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El set en Python garantiza que los elementos sean únicos, lo que es ideal para almacenar datos sin duplicados."
},
{
    "id": "py-122",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Al limpiar datos en un DataFrame de pandas, ¿qué método elimina las filas con valores nulos?",
    "opciones": [
        "A. dropna()",
        "B. removena()",
        "C. delete_nulls()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "dropna() es el método estándar de pandas para eliminar filas o columnas con valores nulos."
},
{
    "id": "py-123",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un script ETL, el Gestor II necesita combinar dos DataFrames por una columna llamada 'NIT'. ¿Qué función de pandas es adecuada?",
    "opciones": [
        "A. pd.concat()",
        "B. pd.merge()",
        "C. pd.join()"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "pd.merge() permite unir DataFrames usando una clave común como 'NIT', asegurando la coherencia en la integración de datos."
},
{
    "id": "py-124",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para contar el número de facturas por contribuyente en un DataFrame, ¿qué función de pandas se recomienda?",
    "opciones": [
        "A. groupby().count()",
        "B. countrows()",
        "C. sum().count()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "groupby().count() permite agrupar por una columna y contar registros asociados, útil para análisis por contribuyente."
},
{
    "id": "py-125",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, ¿cómo se crea una función que retorne el doble de un valor ingresado?",
    "opciones": [
        "A. def doble(x): return x*2",
        "B. doble(x) = x*2",
        "C. function doble(x) { return x*2 }"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La sintaxis def nombre_funcion(param): return valor es la forma correcta de definir funciones en Python."
},
{
    "id": "py-126",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para verificar si la variable 'monto' es mayor que 1000 en Python, ¿qué instrucción es correcta?",
    "opciones": [
        "A. if monto > 1000:",
        "B. if monto => 1000:",
        "C. if monto >> 1000:"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La sintaxis correcta para comparar en Python es usando '>' sin otros símbolos adicionales."
},
{
    "id": "py-127",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "El Gestor II necesita obtener las primeras 10 filas de un DataFrame llamado df. ¿Qué comando usar?",
    "opciones": [
        "A. df.top(10)",
        "B. df.head(10)",
        "C. df.first(10)"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El método df.head(n) devuelve las primeras n filas de un DataFrame, siendo el estándar en pandas."
},
{
    "id": "py-128",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un script de Python, ¿cuál es la forma correcta de importar pandas con un alias estándar?",
    "opciones": [
        "A. import pandas as pd",
        "B. import pandas as pds",
        "C. import pandas_pd"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "import pandas as pd es la convención más utilizada y reconocida para importar la librería pandas."
},

{
    "id": "py-129",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un script de la DIAN, se requiere convertir una lista en un DataFrame. ¿Qué función de pandas se debe usar?",
    "opciones": [
        "A. pd.DataFrame(lista)",
        "B. pd.list_to_df(lista)",
        "C. pd.frame(lista)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "pd.DataFrame(lista) es la forma correcta de convertir listas o listas de listas en un DataFrame en pandas."
},
{
    "id": "py-130",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si se necesita instalar la librería pandas en un entorno de trabajo de la DIAN, ¿qué comando de terminal se usa?",
    "opciones": [
        "A. pip install pandas",
        "B. install pandas",
        "C. python pandas install"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El comando estándar para instalar librerías en Python es pip install nombre_libreria, en este caso pip install pandas."
},
{
    "id": "py-131",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para concatenar dos DataFrames verticalmente en pandas, ¿qué función es adecuada?",
    "opciones": [
        "A. pd.concat([df1, df2])",
        "B. pd.merge([df1, df2])",
        "C. pd.join([df1, df2])"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "pd.concat() permite unir DataFrames por filas o columnas dependiendo del parámetro axis, útil para agregar datos similares."
},
{
    "id": "py-132",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, ¿cómo se asigna el valor 500 a una variable llamada monto?",
    "opciones": [
        "A. monto = 500",
        "B. monto == 500",
        "C. var monto = 500"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "En Python, el operador '=' se usa para asignar valores a variables."
},
{
    "id": "py-133",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "El Gestor II quiere saber cuántos registros únicos hay en la columna 'NIT' de un DataFrame df. ¿Qué método usar?",
    "opciones": [
        "A. df['NIT'].nunique()",
        "B. df['NIT'].unique_count()",
        "C. df['NIT'].countunique()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "nunique() devuelve el número de valores únicos en una serie o columna de un DataFrame."
},
{
    "id": "py-134",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para obtener un resumen estadístico de un DataFrame en pandas, ¿qué método se utiliza?",
    "opciones": [
        "A. df.describe()",
        "B. df.summary()",
        "C. df.stats()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "df.describe() genera un resumen estadístico de las columnas numéricas, útil para análisis inicial de datos."
},
{
    "id": "py-135",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si se necesita ordenar un DataFrame por la columna 'monto' en orden descendente, ¿qué comando usar?",
    "opciones": [
        "A. df.sort_values('monto', ascending=False)",
        "B. df.sort('monto', reverse=True)",
        "C. df.order_by('monto', desc=True)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "sort_values() es el método de pandas para ordenar DataFrames, con el parámetro ascending=False para orden descendente."
},
{
    "id": "py-136",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, ¿qué símbolo se usa para los comentarios en una sola línea?",
    "opciones": [
        "A. //",
        "B. #",
        "C. --"
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "En Python, el símbolo '#' se usa para comentarios de una sola línea."
},
{
    "id": "py-137",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para guardar un DataFrame en un archivo CSV sin incluir el índice, ¿qué comando se usa?",
    "opciones": [
        "A. df.to_csv('archivo.csv', index=False)",
        "B. df.save_csv('archivo.csv', no_index=True)",
        "C. df.export_csv('archivo.csv', ignore_index=True)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El método to_csv() con el parámetro index=False guarda el DataFrame sin incluir el índice."
},
{
    "id": "py-138",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, ¿qué operador se utiliza para comprobar si un valor existe en una lista?",
    "opciones": [
        "A. in",
        "B. exists",
        "C. contains"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El operador in permite verificar si un elemento se encuentra dentro de una lista, tupla o conjunto."
},

{
    "id": "py-139",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un proceso ETL de la DIAN, un Gestor II necesita unir dos DataFrames df1 y df2 por la columna 'NIT'. ¿Qué función de pandas debe usar para un 'inner join'?",
    "opciones": [
        "A. pd.merge(df1, df2, on='NIT', how='inner')",
        "B. pd.concat([df1, df2], axis=1)",
        "C. df1.join(df2, on='NIT', type='inner')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "pd.merge con el parámetro how='inner' es la forma correcta de realizar un inner join en pandas, asegurando que solo se incluyan coincidencias exactas en la columna clave."
},
{
    "id": "py-140",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si se necesita calcular la media de la columna 'valor' en un DataFrame df, ¿qué método es el más apropiado?",
    "opciones": [
        "A. df['valor'].mean()",
        "B. df['valor'].average()",
        "C. df['valor'].sum() / df['valor'].count()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "mean() es el método directo en pandas para calcular el promedio de una serie numérica, optimizando la sintaxis y legibilidad."
},
{
    "id": "py-141",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe detectar y eliminar filas duplicadas en un DataFrame. ¿Qué método de pandas debe utilizar?",
    "opciones": [
        "A. df.drop_duplicates()",
        "B. df.remove_duplicates()",
        "C. df.delete_duplicates()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "drop_duplicates() es el método estándar de pandas para eliminar registros duplicados de un DataFrame."
},
{
    "id": "py-142",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para reemplazar todos los valores nulos en la columna 'monto' con cero, ¿qué comando se debe usar?",
    "opciones": [
        "A. df['monto'].fillna(0, inplace=True)",
        "B. df['monto'].replace_na(0, inplace=True)",
        "C. df['monto'].null_to_zero()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "fillna() permite sustituir valores nulos en una columna o DataFrame, asegurando la consistencia en cálculos posteriores."
},
{
    "id": "py-143",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si se requiere agrupar un DataFrame por 'departamento' y sumar la columna 'ventas', ¿qué comando es correcto?",
    "opciones": [
        "A. df.groupby('departamento')['ventas'].sum()",
        "B. df.group('departamento').sum('ventas')",
        "C. df['ventas'].groupby('departamento').sum()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "groupby() seguido de sum() es la forma más eficiente de agrupar datos por categorías y realizar sumatorias."
},
{
    "id": "py-144",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita leer datos en formato JSON desde un archivo en Python. ¿Qué método de pandas es adecuado?",
    "opciones": [
        "A. pd.read_json('archivo.json')",
        "B. pd.load_json('archivo.json')",
        "C. json.read('archivo.json')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "pandas ofrece read_json() para importar datos en formato JSON directamente a un DataFrame."
},
{
    "id": "py-145",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, para crear una función que devuelva el doble de un número, ¿cuál es la sintaxis correcta?",
    "opciones": [
        "A. def doble(x): return x * 2",
        "B. function doble(x): return x * 2",
        "C. def doble(x) => x * 2"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La palabra clave def se usa en Python para definir funciones, seguida del nombre, parámetros y return."
},
{
    "id": "py-146",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si un DataFrame df tiene una columna 'fecha' en formato texto, ¿qué función de pandas convierte a tipo datetime?",
    "opciones": [
        "A. pd.to_datetime(df['fecha'])",
        "B. df['fecha'].to_date()",
        "C. convert.date(df['fecha'])"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "pd.to_datetime() convierte series o columnas a formato de fecha y hora estándar en pandas."
},
{
    "id": "py-147",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para iterar sobre un DataFrame fila por fila, ¿qué método de pandas se recomienda?",
    "opciones": [
        "A. df.iterrows()",
        "B. df.rows()",
        "C. df.for_each()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "iterrows() devuelve un iterador que permite recorrer un DataFrame por filas, útil en operaciones fila a fila."
},
{
    "id": "py-148",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un script de la DIAN, se necesita calcular el número total de registros en un DataFrame df. ¿Qué método es correcto?",
    "opciones": [
        "A. len(df)",
        "B. df.count_rows()",
        "C. df.length()"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "len(df) devuelve el número total de filas en un DataFrame en Python."
},
{
    "id": "py-149",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para combinar dos DataFrames con las mismas columnas, uno encima del otro, ¿qué comando es más apropiado?",
    "opciones": [
        "A. pd.concat([df1, df2])",
        "B. df1.merge(df2)",
        "C. df1.append_rows(df2)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "pd.concat() permite unir DataFrames verticalmente si comparten las mismas columnas."
},
{
    "id": "py-150",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II quiere calcular el valor máximo de la columna 'ingresos'. ¿Qué método de pandas debe usar?",
    "opciones": [
        "A. df['ingresos'].max()",
        "B. df['ingresos'].maximum()",
        "C. max(df['ingresos'])"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "max() aplicado a una serie de pandas devuelve el valor máximo de la misma."
},
{
    "id": "py-151",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un análisis, se requiere seleccionar solo las filas donde 'ciudad' sea igual a 'Bogotá'. ¿Qué comando es correcto?",
    "opciones": [
        "A. df[df['ciudad'] == 'Bogotá']",
        "B. df.select(ciudad='Bogotá')",
        "C. df.where('ciudad', 'Bogotá')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "La indexación booleana df[condición] es el método más usado en pandas para filtrar filas según criterios."
},
{
    "id": "py-152",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si se quiere eliminar la columna 'monto' de un DataFrame, ¿qué comando se debe usar?",
    "opciones": [
        "A. df.drop('monto', axis=1, inplace=True)",
        "B. df.remove_column('monto')",
        "C. df.delete('monto')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "drop() con axis=1 es el método estándar para eliminar columnas en pandas."
},
{
    "id": "py-153",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, para importar solo la función sqrt de la librería math, ¿qué comando se usa?",
    "opciones": [
        "A. from math import sqrt",
        "B. import sqrt from math",
        "C. use math.sqrt"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "from math import sqrt importa únicamente la función sqrt desde el módulo math."
},
{
    "id": "py-154",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II quiere reemplazar todas las apariciones de 'DIAN' por 'Entidad' en la columna 'origen'. ¿Qué método usar?",
    "opciones": [
        "A. df['origen'].replace('DIAN', 'Entidad', inplace=True)",
        "B. df['origen'].change('DIAN', 'Entidad')",
        "C. df['origen'].update('DIAN', 'Entidad')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "replace() permite sustituir valores específicos en una serie o columna de pandas."
},
{
    "id": "py-155",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En Python, ¿cuál es la estructura correcta de un bucle for para iterar del 1 al 5?",
    "opciones": [
        "A. for i in range(1, 6):",
        "B. for i from 1 to 5:",
        "C. for i = 1 to 5:"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "range(1, 6) genera los números del 1 al 5, y es la forma estándar de iterar en Python."
},
{
    "id": "py-156",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para leer un archivo CSV separado por punto y coma en pandas, ¿qué comando es correcto?",
    "opciones": [
        "A. pd.read_csv('archivo.csv', sep=';')",
        "B. pd.read_csv('archivo.csv', delimiter='comma')",
        "C. pd.read_csv('archivo.csv', separator=';')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "read_csv() admite el parámetro sep para especificar el delimitador, en este caso ';'."
},
{
    "id": "py-157",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si se requiere seleccionar múltiples columnas de un DataFrame, ¿qué sintaxis es correcta?",
    "opciones": [
        "A. df[['col1', 'col2']]",
        "B. df['col1', 'col2']",
        "C. df.select('col1', 'col2')"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Para seleccionar varias columnas en pandas, se debe pasar una lista de nombres de columnas dentro de dobles corchetes."
},

{
    "id": "py-158",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II detecta que una consulta de pandas con múltiples merges está tardando demasiado en DataR. ¿Qué técnica podría optimizar el rendimiento?",
    "opciones": [
        "A. Establecer índices en las columnas clave antes de hacer el merge.",
        "B. Dividir los merges en múltiples DataFrames y unirlos manualmente.",
        "C. Convertir todos los datos a listas y procesarlos sin pandas."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Definir índices en las columnas clave antes de hacer un merge mejora significativamente el rendimiento, sobre todo con grandes volúmenes de datos."
},
{
    "id": "py-159",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Durante un proceso ETL en Python, el Gestor II nota que los valores nulos se propagan en las operaciones aritméticas. ¿Qué solución es más eficiente?",
    "opciones": [
        "A. Usar fillna() antes de las operaciones para reemplazar nulos por un valor definido.",
        "B. Eliminar todas las filas con valores nulos antes del procesamiento.",
        "C. Convertir los nulos a texto 'NULL' para mantenerlos visibles."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Usar fillna() permite imputar valores y evitar errores o propagación de nulos en cálculos, manteniendo la integridad de datos."
},

{
    "id": "py-160",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un análisis tributario, se requiere aplicar una función compleja a cada fila del DataFrame. ¿Qué método es más eficiente que iterrows()?",
    "opciones": [
        "A. apply() con axis=1",
        "B. for-loop clásico en Python",
        "C. smap() sobre la columna"
    ],

    "respuesta_correcta_index": 0,
    "explicacion": "apply() con axis=1 aplica una función fila a fila, siendo más rápido que iterrows() en la mayoría de casos."
},
{
    "id": "py-161",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si un script para la DIAN requiere leer 10 millones de registros desde CSV, ¿qué ajuste en read_csv() mejorará la eficiencia?",
    "opciones": [
        "A. Definir el parámetro dtype para cada columna.",
        "B. Usar sep=';' en todas las lecturas.",
        "C. Leer el archivo línea por línea con open()."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Definir dtypes optimiza la memoria y velocidad de carga, crítico para grandes volúmenes en entornos como DataR."
},
{
    "id": "py-162",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II necesita crear una vista filtrada en pandas que se actualice si cambia el DataFrame original. ¿Qué método garantiza esta referencia?",
    "opciones": [
        "A. Usar loc[] para seleccionar el subconjunto.",
        "B. Crear una copia explícita con copy().",
        "C. Convertir el DataFrame a CSV y volver a leerlo."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "loc[] retorna una vista en ciertos casos, permitiendo que cambios en el DataFrame original se reflejen en el subconjunto."
},
{
    "id": "py-163",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En un análisis de inconsistencias tributarias, se necesita comparar dos DataFrames por todas sus columnas. ¿Qué función es más eficiente?",
    "opciones": [
        "A. df1.equals(df2)",
        "B. df1.compare(df2)",
        "C. df1.diff(df2)"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "equals() evalúa si dos DataFrames son exactamente iguales en datos y estructura."
},
{
    "id": "py-164",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si el Gestor II implementa un pipeline ETL en Python, ¿qué librería es más adecuada para paralelizar tareas de transformación?",
    "opciones": [
        "A. Dask",
        "B. os",
        "C. math"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Dask permite manejar grandes volúmenes de datos y paralelizar tareas ETL aprovechando múltiples núcleos."
},
{
    "id": "py-165",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para proteger datos personales conforme a la Ley 1581, ¿qué práctica en Python es adecuada antes de exportar un DataFrame?",
    "opciones": [
        "A. Anonimizar o encriptar las columnas con datos sensibles.",
        "B. Exportar el DataFrame completo sin modificaciones.",
        "C. Guardar el archivo en texto plano."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Anonimizar o encriptar cumple la Ley 1581 y evita exposición de datos personales."
},
{
    "id": "py-166",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Si en un reporte a la UGPP se repiten cálculos costosos, ¿qué técnica en Python mejorará el rendimiento?",
    "opciones": [
        "A. Almacenar resultados en variables intermedias.",
        "B. Recalcular todo en cada paso.",
        "C. Usar time.sleep() para distribuir la carga."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Guardar resultados evita recalcular operaciones pesadas, mejorando la eficiencia."
},
{
    "id": "py-167",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Para validar el formato de correos electrónicos en una columna, ¿qué herramienta de Python es más eficiente?",
    "opciones": [
        "A. Expresiones regulares con re.match()",
        "B. str.contains() sin patrón específico",
        "C. Filtrar por longitud de texto"
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Las regex permiten validar el patrón correcto de correos, asegurando consistencia de datos."
},

{
"id": "py-168",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Un pipeline en la DIAN debe leer archivos CSV de gran tamaño (10+ GB). ¿Qué enfoque en Python reduce uso de memoria sin perder capacidad de validación por lotes?",
"opciones": [
"A. Usar pd.read_csv con chunksize y procesar por bloques.",
"B. Convertir el CSV a listas y recorrer con for clásico.",
"C. Leer todo el CSV completo y luego filtrar en memoria."
],
"respuesta_correcta_index": 0,
"explicacion": "El parámetro chunksize de pd.read_csv permite procesar por lotes y validar cada bloque, reduciendo uso de memoria y facilitando controles de calidad durante ETL."
},
{
"id": "py-169",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se requiere asegurar trazabilidad de transformaciones sobre un DataFrame con información sensible. ¿Qué práctica en Python favorece auditabilidad?",
"opciones": [
"A. Registrar pasos con logging y conservar copias versionadas.",
"B. Sobrescribir el DataFrame en cada paso para ahorrar espacio.",
"C. Exportar solo el resultado final sin registrar pasos intermedios."
],
"respuesta_correcta_index": 0,
"explicacion": "El uso de logging estructurado y versionado de artefactos permite reconstruir el linaje del dato, favoreciendo auditorías y cumplimiento de Gobierno de Datos."
},
{
"id": "py-170",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Un Gestor II detecta que una función aplicada con apply(axis=1) es lenta. ¿Qué alternativa suele mejorar rendimiento en pandas?",
"opciones": [
"A. Reescribir la lógica con operaciones vectorizadas o np.where.",
"B. Usar iterrows para tener control fila a fila.",
"C. Convertir el DataFrame a diccionario y recorrer claves."
],
"respuesta_correcta_index": 0,
"explicacion": "Las operaciones vectorizadas y funciones como np.where explotan optimizaciones internas de NumPy/pandas, superando en rendimiento a apply y a iteraciones fila a fila."
},
{
"id": "py-171",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Para validar estructura UBL 2.1 de facturas electrónicas antes de cargar a DataR, ¿qué enfoque en Python es más robusto?",
"opciones": [
"A. Validar contra un esquema XML (XSD) usando lxml.etree.",
"B. Buscar etiquetas con find() y asumir estructura correcta.",
"C. Convertir a texto plano y revisar con reglas manuales."
],
"respuesta_correcta_index": 0,
"explicacion": "La validación contra XSD con lxml.etree garantiza conformidad estructural UBL 2.1 de manera formal antes de la carga, reduciendo errores y rechazos posteriores."
},
{
"id": "py-172",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se requiere anonimizar NIT y correos en un DataFrame. ¿Qué práctica en Python se ajusta a principios de minimización de datos?",
"opciones": [
"A. Hashear columnas sensibles con SHA-256 y sal.",
"B. Reemplazar por 'XXX' todos los campos personales.",
"C. Eliminar todas las columnas sin evaluar su uso analítico."
],
"respuesta_correcta_index": 0,
"explicacion": "El hash con sal conserva unicidad para análisis estadístico sin exponer datos personales, alineado con minimización y privacidad por diseño."
},
{
"id": "py-173",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Un lote ETL falla intermitentemente por timeouts al consumir un API. ¿Qué patrón de código en Python mejora resiliencia?",
"opciones": [
"A. Reintentos exponenciales con backoff y manejo de excepciones.",
"B. Aumentar el sleep fijo antes de cada llamada.",
"C. Repetir la misma petición indefinidamente hasta éxito."
],
"respuesta_correcta_index": 0,
"explicacion": "El patrón de reintentos con backoff y captura de excepciones típicas (timeout, conexión) mejora resiliencia y evita saturación del servicio."
},
{
"id": "py-174",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se debe garantizar integridad referencial entre DataFrames 'contribuyentes' y 'facturas'. ¿Qué verificación programática ayuda antes de un merge?",
"opciones": [
"A. Comprobar duplicados y nulos en claves con df.key.nunique y df.key.isna.",
"B. Ordenar DataFrames por la clave sin validaciones previas.",
"C. Concatenar y dejar que el sistema resuelva inconsistencias."
],
"respuesta_correcta_index": 0,
"explicacion": "Verificar ausencia de nulos/duplicados en claves evita uniones erróneas y asegura que el merge refleje relaciones 1:N o 1:1 correctamente."
},
{
"id": "py-175",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Para detectar outliers en montos declarados usando Python, ¿qué aproximación reproducible sugiere un Gestor II?",
"opciones": [
"A. Regla IQR con límites Q1−1.5IQR y Q3+1.5IQR.",
"B. Eliminar valores máximos y mínimos sin criterio.",
"C. Redondear todos los montos a la media general."
],
"respuesta_correcta_index": 0,
"explicacion": "La regla IQR es un método estándar y reproducible para detectar atípicos, útil en controles previos a análisis o cargas oficiales."
},
{
"id": "py-176",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Un DataFrame presenta mezcla de tipos en 'monto' (str y float). ¿Qué acción robusta toma el Gestor II?",
"opciones": [
"A. Usar pd.to_numeric(errors='coerce') y tratar nulos resultantes.",
"B. Eliminar filas con strings para uniformar.",
"C. Convertir todo a string para facilitar impresiones."
],
"respuesta_correcta_index": 0,
"explicacion": "pd.to_numeric con coerción normaliza tipos y expone conversiones fallidas como NaN, que luego pueden imputarse o excluirse según regla."
},
{
"id": "py-177",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se requiere acelerar un cálculo numérico intensivo en Python puro. ¿Qué herramienta prioriza desempeño con mínimo cambio?",
"opciones": [
"A. NumPy vectorizado para operaciones por arreglos.",
"B. Reescribir el algoritmo en puro Python con más for.",
"C. Convertir el script en múltiples hilos estándar."
],
"respuesta_correcta_index": 0,
"explicacion": "NumPy aprovecha implementaciones en C y vectorización, logrando grandes mejoras respecto a bucles de Python puro."
},
{
"id": "py-178",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Un informe mensual requiere reproducibilidad exacta. ¿Qué control implementa el Gestor II en Python?",
"opciones": [
"A. Fijar semillas aleatorias y congelar versiones de dependencias.",
"B. Ejecutar manualmente hasta obtener el mismo resultado.",
"C. Usar datos distintos cada mes para mayor variedad."
],
"respuesta_correcta_index": 0,
"explicacion": "Semillas determinísticas y versionado de dependencias garantizan reproducibilidad, fundamental en trazabilidad y control interno."
},
{
"id": "py-179",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Al consolidar pagos, surgen duplicados exactos por reintentos de carga. ¿Qué estrategia en pandas es adecuada?",
"opciones": [
"A. df.drop_duplicates(keep='first') con claves relevantes.",
"B. Ordenar el DataFrame y exportar como está.",
"C. Sumar todas las filas para compensar duplicados."
],
"respuesta_correcta_index": 0,
"explicacion": "drop_duplicates basado en claves de negocio elimina registros replicados y preserva una sola ocurrencia para consistencia."
},
{
"id": "py-180",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Para monitorear un ETL en producción, ¿qué práctica de observabilidad en Python facilita diagnóstico?",
"opciones": [
"A. Logging estructurado por etapas y métricas de tiempo.",
"B. Imprimir en consola pasos críticos sin timestamps.",
"C. Solo revisar el archivo final para confirmar éxito."
],
"respuesta_correcta_index": 0,
"explicacion": "El logging estructurado con tiempos y estados por etapa permite detectar cuellos de botella y fallas específicas rápidamente."
},
{
"id": "py-181",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se requiere convertir fechas heterogéneas ('01/02/24', '2024-02-01'). ¿Qué opción es más robusta?",
"opciones": [
"A. pd.to_datetime(col, dayfirst=True, errors='coerce')",
"B. Reemplazar manualmente todos los separadores con str.replace",
"C. Tomar el primer formato y descartar el resto"
],
"respuesta_correcta_index": 0,
"explicacion": "pd.to_datetime con dayfirst y manejo de errores estandariza formatos y detecta conversiones fallidas de forma controlada."
},
{
"id": "py-182",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Un DataFrame grande requiere cálculo de totales por clave. ¿Qué alternativa escala mejor que groupby en memoria limitada?",
"opciones": [
"A. Dask DataFrame para agrupaciones fuera de memoria.",
"B. Convertir a listas y acumular con bucles.",
"C. Exportar a Excel y usar tablas dinámicas."
],
"respuesta_correcta_index": 0,
"explicacion": "Dask permite procesamiento distribuido y ‘out-of-core’, adecuado para agrupaciones en datasets mayores a la memoria disponible."
},
{
"id": "py-183",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se va a publicar un notebook con datos sensibles en un repositorio interno. ¿Qué control aplicar desde Python?",
"opciones": [
"A. Parametrizar rutas y cargar credenciales desde variables de entorno.",
"B. Codificar usuario y contraseña en texto claro en el notebook.",
"C. Exportar a HTML con las credenciales visibles para facilidad."
],
"respuesta_correcta_index": 0,
"explicacion": "Usar variables de entorno y parámetros evita exponer secretos en código y cumple buenas prácticas de seguridad."
},
{
"id": "py-184",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "El Gestor II debe fusionar DataFrames por múltiples claves ('NIT','Periodo'). ¿Qué asegura un merge correcto?",
"opciones": [
"A. pd.merge(df1, df2, on=['NIT','Periodo'], how='left')",
"B. pd.merge(df1, df2, on='NIT-Periodo', how='left')",
"C. Concatenar primero y luego agrupar por claves"
],
"respuesta_correcta_index": 0,
"explicacion": "El join multicolumna con on=[...] garantiza coincidencia por ambas claves y preserva filas de df1 con how='left'."
},
{
"id": "py-185",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "En una limpieza de direcciones, se busca estandarizar mayúsculas/minúsculas y tildes. ¿Qué enfoque en Python es más adecuado?",
"opciones": [
"A. Normalizar con unicodedata y aplicar .str.normalize/.lower",
"B. Reemplazar manualmente cada vocal por su versión simple",
"C. Convertir todo a MAYÚSCULAS y terminar el proceso"
],
"respuesta_correcta_index": 0,
"explicacion": "La normalización Unicode y métodos de cadena de pandas evitan casos especiales y preservan comparabilidad entre registros."
},
{
"id": "py-186",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Para validar reglas de negocio (por ejemplo, monto>=0) en un DataFrame, ¿qué patrón de código facilita reportes de calidad?",
"opciones": [
"A. Construir un diccionario de checks y generar un informe de incumplimientos.",
"B. Eliminar filas que no cumplan sin reportar detalles.",
"C. Corregir silenciosamente valores negativos a cero."
],
"respuesta_correcta_index": 0,
"explicacion": "Definir checks declarativos y reportar incumplimientos aporta evidencia, facilita remediación y soporta auditorías de datos."
},
{
"id": "py-187",
"tema": "Python (Fundamentos para Datos)",
"pregunta": "Se desea acelerar una transformación compleja repetitiva. ¿Qué técnica de Python ayuda sin comprometer legibilidad?",
"opciones": [
"A. Caching de resultados con functools.lru_cache en funciones puras.",
"B. Intercalar prints para medir rendimiento a ojo.",
"C. Reescribir todo el pipeline en un único one-liner."
],
"respuesta_correcta_index": 0,
"explicacion": "El caching con lru_cache evita recomputar funciones determinísticas, mejora rendimiento y mantiene el código claro y modular."
},


  {
    "id": "py-188",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II está a cargo de un proceso ETL crítico que combina datos de facturación electrónica con registros de la UGPP. El proceso falla repetidamente en la etapa de Transformación debido a que la lógica de negocio para un campo clave ha cambiado sin previo aviso. Esta falla afecta un reporte a la Dirección General. ¿Qué acción debe tomar el Gestor II para mitigar el impacto y asegurar una solución a largo plazo?",
    "opciones": [
      "A. Revertir la última ejecución del proceso ETL, ajustar la lógica de negocio para el nuevo formato y notificar la falla al área de análisis de la entidad.",
      "B. Notificar a la Dirección de Gestión de Impuestos sobre el cambio en la lógica de negocio y solicitar una documentación formal para actualizar el proceso ETL de forma definitiva.",
      "C. Desactivar el proceso ETL hasta que se tenga una solución definitiva y notificar a la Dirección de Gestión de Impuestos que el reporte a la Dirección General no se puede generar."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "El problema se origina en un cambio en la lógica de negocio, lo que afecta la etapa de Transformación. La acción más adecuada es notificar al área responsable del cambio y solicitar una documentación formal para actualizar el proceso ETL, lo que asegura una solución a largo plazo y la consistencia de la información."
  },
  {
    "id": "py-189",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "En la DIAN, un proceso ETL está extrayendo datos de un sistema legado para un almacén de datos (Data Warehouse) de la entidad. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que tiene una alta latencia. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos obsoleta.",
      "B. El flujo de trabajo, que no está diseñado para la extracción de datos en paralelo en la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "Un conector de datos es el componente que se encarga de la conexión con la fuente de datos. Si el conector no está optimizado para una fuente de datos obsoleta, la extracción de los datos puede ser muy lenta y afectar la eficiencia del proceso ETL."
  },
  {
    "id": "py-190",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. El proceso requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-191",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-192",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-193",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-194",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-195",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-196",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-197",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-198",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-199",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-200",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-201",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-202",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-203",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-204",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-205",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-206",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-207",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-208",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-209",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-210",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-211",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-212",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-213",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-214",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-215",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-216",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-217",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-218",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-219",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-220",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-221",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-222",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-223",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-224",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-225",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-226",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-227",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-228",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-229",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-230",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-231",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-232",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-233",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-234",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-235",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-236",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-237",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-238",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-239",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-240",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-241",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-242",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-243",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-244",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-245",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-246",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-247",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-248",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-249",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-250",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-251",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-252",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-253",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-254",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-255",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-256",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-257",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-258",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-259",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-260",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-261",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-262",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-263",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-264",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-265",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-266",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-267",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-268",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-269",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-270",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-271",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-272",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-273",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-274",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-275",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-276",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-277",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-278",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-279",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-280",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-281",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-282",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-283",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-284",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-285",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-286",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-287",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-288",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-289",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-290",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-291",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-292",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-293",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-294",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-295",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-296",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-297",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-298",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-299",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-300",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-301",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-302",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-303",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-304",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-305",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-306",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-307",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-308",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-309",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-310",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-311",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-312",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-313",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-314",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  },
  {
    "id": "py-315",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está cargando datos de facturación electrónica a un almacén de datos (Data Warehouse). La herramienta de monitoreo del proceso indica que la etapa de Carga es muy lenta, lo que afecta la disponibilidad de la información para el análisis. ¿Qué componente de la herramienta ETL podría ser el origen de este problema?",
    "opciones": [
      "A. El conector de datos, que no está optimizado para la fuente de datos de la entidad.",
      "B. El destino de carga, que tiene una alta latencia o una capacidad limitada para recibir los datos de la entidad.",
      "C. Las reglas de transformación, que están generando errores en el formato de los datos de la entidad."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La lentitud en la etapa de Carga se debe a que el destino de carga tiene una alta latencia o una capacidad limitada para recibir los datos. Un destino con estas características afecta la eficiencia del proceso ETL, lo que compromete la disponibilidad de la información para el análisis."
  },
  {
    "id": "py-316",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar información de facturación electrónica y registros aduaneros para la detección de contrabando. La solución requiere anonimizar ciertos datos personales de los contribuyentes para cumplir con la Ley 1581 de 2012. ¿Qué etapa del proceso ETL se encarga de la anonimización de la información?",
    "opciones": [
      "A. La etapa de extracción, que obtiene los datos anonimizados de la fuente original.",
      "B. La etapa de transformación, que se encarga de la limpieza y la anonimización de los datos.",
      "C. La etapa de carga, que mueve los datos anonimizados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La anonimización de los datos es una tarea de transformación. Se realiza en esta etapa para que los datos cumplan con la política de privacidad y la Ley 1581 de 2012 antes de ser movidos al repositorio de destino para el análisis."
  },
  {
    "id": "py-317",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un proceso ETL de la DIAN está extrayendo información de declaraciones aduaneras. La herramienta de monitoreo del proceso indica una alta tasa de fallos en la etapa de Extracción. Después de investigar, se descubre que la fuente de datos es un sistema obsoleto que no responde a las peticiones del conector de datos. ¿Qué acción debe tomar el Gestor II para resolver este problema?",
    "opciones": [
      "A. Notificar a la Dirección de Gestión de Aduanas que su sistema obsoleto no es compatible con el proceso ETL y que debe ser actualizado.",
      "B. Implementar una solución de ETL que se adapte al sistema obsoleto, para que la extracción se realice de manera manual y sin fallos.",
      "C. Configurar un conector de datos que se adapte al sistema obsoleto de la entidad, para que la extracción se realice de manera gradual y sin fallos, y notificar a la Dirección de Aduanas sobre el problema."
    ],
    "respuesta_correcta_index": 0,
    "explicacion": "El problema de la alta tasa de fallos en la etapa de Extracción se debe a que la fuente de datos es un sistema obsoleto. La acción más adecuada es notificar a la Dirección de Gestión de Aduanas para que el sistema sea actualizado, ya que la DIAN requiere la información de manera oportuna para la fiscalización."
  },
  {
    "id": "py-318",
    "tema": "Python (Fundamentos para Datos)",
    "pregunta": "Un Gestor II debe diseñar un proceso ETL para combinar datos de facturación electrónica y registros aduaneros. El proceso requiere la eliminación de los registros duplicados de los contribuyentes. ¿Qué etapa del proceso ETL se encarga de eliminar estos registros duplicados?",
    "opciones": [
      "A. En la etapa de extracción, para obtener los datos sin duplicados desde su origen.",
      "B. En la etapa de transformación, que se encarga de la limpieza y la eliminación de los duplicados.",
      "C. En la etapa de carga, para mover los datos sin duplicados al repositorio de destino."
    ],
    "respuesta_correcta_index": 1,
    "explicacion": "La limpieza de datos, que incluye la eliminación de registros duplicados, es una tarea que se realiza en la etapa de transformación. Esta acción asegura la calidad de la información antes de ser movida al repositorio de destino para el análisis."
  }









]